{
  "eccn": "4E091",
  "normalized": "4E091",
  "history": [
    {
      "version": "2025-01-16",
      "fetchedAt": "2025-10-02T20:33:49.999Z",
      "sourceUrl": "https://www.ecfr.gov/api/versioner/v1/full/2025-01-16/title-15?format=xml",
      "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "title": "'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "category": "4",
      "group": "4E",
      "supplement": {
        "number": "1",
        "heading": "Supplement No. 1 to Part 774—The Commerce Control List"
      },
      "breadcrumbs": [
        "E. “Technology”"
      ],
      "ancestors": [],
      "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'\n4E091 'Parameters' for an artificial intelligence model trained utilizing 10\n26\nor more 'operations.'\nLicense Requirements\nReason for Control:\nRS, AT\nControl(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.\nControl(s)\nCountry Chart\n(see Supp. No. 1\nto part 738)\nRS applies entire entry\nTo or within any destination worldwide. See § 742.6(a)(13).\nAT applies to entire entry\nAT Column 1.\nList Based License Exceptions (See Part 740 for a Description of All License Exceptions)\nTSR:\nN/A\nAIA:\nYes\nACM:\nNo\nSpecial Conditions for STA\nSTA:\nLicense Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR).\nList of Items Controlled\nRelated Controls:\nN/A\nRelated Definition:\nN/A\nItems:\nThe list of items controlled is contained in the ECCN heading.\nTechnical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.\nNotes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
      "structure": {
        "identifier": "4E091",
        "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "label": "4E091 – 4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "content": [
          {
            "type": "text",
            "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10"
          },
          {
            "type": "text",
            "text": "26"
          },
          {
            "type": "text",
            "text": "or more 'operations.'"
          },
          {
            "type": "text",
            "text": "License Requirements"
          },
          {
            "type": "text",
            "text": "Reason for Control:"
          },
          {
            "type": "text",
            "text": "RS, AT"
          },
          {
            "type": "html",
            "tag": "TABLE",
            "html": "<TABLE border=\"1\" cellpadding=\"1\" cellspacing=\"1\" class=\"gpo_table\" frame=\"void\" width=\"100%\">\n<THEAD>\n<TR>\n<TH class=\"center\">Control(s)</TH>\n<TH class=\"center\">Country Chart\n<br/>(see Supp. No. 1\n<br/>to part 738)</TH>\n</TR>\n</THEAD>\n<TBODY>\n<TR>\n<TD class=\"left\">RS applies entire entry</TD>\n<TD class=\"left\">To or within any destination worldwide. See § 742.6(a)(13).</TD>\n</TR>\n<TR>\n<TD class=\"left\">AT applies to entire entry (4E091)</TD>\n<TD class=\"left\">AT Column 1.</TD>\n</TR>\n</TBODY>\n</TABLE>",
            "text": "Control(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.",
            "id": null
          },
          {
            "type": "text",
            "text": "Control(s)"
          },
          {
            "type": "text",
            "text": "Country Chart"
          },
          {
            "type": "text",
            "text": "(see Supp. No. 1"
          },
          {
            "type": "text",
            "text": "to part 738)"
          },
          {
            "type": "text",
            "text": "RS applies entire entry"
          },
          {
            "type": "text",
            "text": "To or within any destination worldwide. See § 742.6(a)(13)."
          },
          {
            "type": "text",
            "text": "AT applies to entire entry"
          },
          {
            "type": "text",
            "text": "AT Column 1."
          },
          {
            "type": "text",
            "text": "List Based License Exceptions (See Part 740 for a Description of All License Exceptions)"
          },
          {
            "type": "text",
            "text": "TSR:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "AIA:"
          },
          {
            "type": "text",
            "text": "Yes"
          },
          {
            "type": "text",
            "text": "ACM:"
          },
          {
            "type": "text",
            "text": "No"
          },
          {
            "type": "text",
            "text": "Special Conditions for STA"
          },
          {
            "type": "text",
            "text": "STA:"
          },
          {
            "type": "text",
            "text": "License Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR)."
          },
          {
            "type": "text",
            "text": "List of Items Controlled"
          },
          {
            "type": "text",
            "text": "Related Controls:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Related Definition:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Items:"
          },
          {
            "type": "text",
            "text": "The list of items controlled is contained in the ECCN heading."
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Technical Notes:</I></HED>\n<P><I>For the purposes of 4E091:</I></P>\n<P><I>1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights.</I></P>\n<P><I>2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP.</I></P>\n<P><I>3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.</I></P></NOTE>",
            "text": "Technical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.",
            "id": null
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Notes:</I></HED>\n<P><I>1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10\n<SU>25</SU> 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher.</I></P>\n<P><I>2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements.</I></P>\n<P><I>2.a. An exporter may determine whether an AI model falls within this exclusion by either:</I></P>\n<P><I>2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or</I></P>\n<P><I>2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.</I></P></NOTE>",
            "text": "Notes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
            "id": null
          }
        ],
        "isEccn": true,
        "boundToParent": false,
        "requireAllChildren": false
      }
    },
    {
      "version": "2025-02-11",
      "fetchedAt": "2025-10-02T20:33:50.452Z",
      "sourceUrl": "https://www.ecfr.gov/api/versioner/v1/full/2025-02-11/title-15?format=xml",
      "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "title": "'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "category": "4",
      "group": "4E",
      "supplement": {
        "number": "1",
        "heading": "Supplement No. 1 to Part 774—The Commerce Control List"
      },
      "breadcrumbs": [
        "E. “Technology”"
      ],
      "ancestors": [],
      "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'\n4E091 'Parameters' for an artificial intelligence model trained utilizing 10\n26\nor more 'operations.'\nLicense Requirements\nReason for Control:\nRS, AT\nControl(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.\nControl(s)\nCountry Chart\n(see Supp. No. 1\nto part 738)\nRS applies entire entry\nTo or within any destination worldwide. See § 742.6(a)(13).\nAT applies to entire entry\nAT Column 1.\nList Based License Exceptions (See Part 740 for a Description of All License Exceptions)\nTSR:\nN/A\nAIA:\nYes\nACM:\nNo\nSpecial Conditions for STA\nSTA:\nLicense Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR).\nList of Items Controlled\nRelated Controls:\nN/A\nRelated Definition:\nN/A\nItems:\nThe list of items controlled is contained in the ECCN heading.\nTechnical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.\nNotes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
      "structure": {
        "identifier": "4E091",
        "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "label": "4E091 – 4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "content": [
          {
            "type": "text",
            "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10"
          },
          {
            "type": "text",
            "text": "26"
          },
          {
            "type": "text",
            "text": "or more 'operations.'"
          },
          {
            "type": "text",
            "text": "License Requirements"
          },
          {
            "type": "text",
            "text": "Reason for Control:"
          },
          {
            "type": "text",
            "text": "RS, AT"
          },
          {
            "type": "html",
            "tag": "TABLE",
            "html": "<TABLE border=\"1\" cellpadding=\"1\" cellspacing=\"1\" class=\"gpo_table\" frame=\"void\" width=\"100%\">\n<THEAD>\n<TR>\n<TH class=\"center\">Control(s)</TH>\n<TH class=\"center\">Country Chart\n<br/>(see Supp. No. 1\n<br/>to part 738)</TH>\n</TR>\n</THEAD>\n<TBODY>\n<TR>\n<TD class=\"left\">RS applies entire entry</TD>\n<TD class=\"left\">To or within any destination worldwide. See § 742.6(a)(13).</TD>\n</TR>\n<TR>\n<TD class=\"left\">AT applies to entire entry (4E091)</TD>\n<TD class=\"left\">AT Column 1.</TD>\n</TR>\n</TBODY>\n</TABLE>",
            "text": "Control(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.",
            "id": null
          },
          {
            "type": "text",
            "text": "Control(s)"
          },
          {
            "type": "text",
            "text": "Country Chart"
          },
          {
            "type": "text",
            "text": "(see Supp. No. 1"
          },
          {
            "type": "text",
            "text": "to part 738)"
          },
          {
            "type": "text",
            "text": "RS applies entire entry"
          },
          {
            "type": "text",
            "text": "To or within any destination worldwide. See § 742.6(a)(13)."
          },
          {
            "type": "text",
            "text": "AT applies to entire entry"
          },
          {
            "type": "text",
            "text": "AT Column 1."
          },
          {
            "type": "text",
            "text": "List Based License Exceptions (See Part 740 for a Description of All License Exceptions)"
          },
          {
            "type": "text",
            "text": "TSR:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "AIA:"
          },
          {
            "type": "text",
            "text": "Yes"
          },
          {
            "type": "text",
            "text": "ACM:"
          },
          {
            "type": "text",
            "text": "No"
          },
          {
            "type": "text",
            "text": "Special Conditions for STA"
          },
          {
            "type": "text",
            "text": "STA:"
          },
          {
            "type": "text",
            "text": "License Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR)."
          },
          {
            "type": "text",
            "text": "List of Items Controlled"
          },
          {
            "type": "text",
            "text": "Related Controls:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Related Definition:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Items:"
          },
          {
            "type": "text",
            "text": "The list of items controlled is contained in the ECCN heading."
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Technical Notes:</I></HED>\n<P><I>For the purposes of 4E091:</I></P>\n<P><I>1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights.</I></P>\n<P><I>2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP.</I></P>\n<P><I>3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.</I></P></NOTE>",
            "text": "Technical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.",
            "id": null
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Notes:</I></HED>\n<P><I>1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10\n<SU>25</SU> 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher.</I></P>\n<P><I>2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements.</I></P>\n<P><I>2.a. An exporter may determine whether an AI model falls within this exclusion by either:</I></P>\n<P><I>2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or</I></P>\n<P><I>2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.</I></P></NOTE>",
            "text": "Notes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
            "id": null
          }
        ],
        "isEccn": true,
        "boundToParent": false,
        "requireAllChildren": false
      }
    },
    {
      "version": "2025-09-28",
      "fetchedAt": "2025-10-02T20:33:50.918Z",
      "sourceUrl": "https://www.ecfr.gov/api/versioner/v1/full/2025-09-28/title-15?format=xml",
      "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "title": "'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "category": "4",
      "group": "4E",
      "supplement": {
        "number": "1",
        "heading": "Supplement No. 1 to Part 774—The Commerce Control List"
      },
      "breadcrumbs": [
        "E. “Technology”"
      ],
      "ancestors": [],
      "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'\n4E091 'Parameters' for an artificial intelligence model trained utilizing 10\n26\nor more 'operations.'\nLicense Requirements\nReason for Control:\nRS, AT\nControl(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.\nControl(s)\nCountry Chart\n(see Supp. No. 1\nto part 738)\nRS applies entire entry\nTo or within any destination worldwide. See § 742.6(a)(13).\nAT applies to entire entry\nAT Column 1.\nList Based License Exceptions (See Part 740 for a Description of All License Exceptions)\nTSR:\nN/A\nAIA:\nYes\nACM:\nNo\nSpecial Conditions for STA\nSTA:\nLicense Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR).\nList of Items Controlled\nRelated Controls:\nN/A\nRelated Definition:\nN/A\nItems:\nThe list of items controlled is contained in the ECCN heading.\nTechnical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.\nNotes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
      "structure": {
        "identifier": "4E091",
        "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "label": "4E091 – 4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "content": [
          {
            "type": "text",
            "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10"
          },
          {
            "type": "text",
            "text": "26"
          },
          {
            "type": "text",
            "text": "or more 'operations.'"
          },
          {
            "type": "text",
            "text": "License Requirements"
          },
          {
            "type": "text",
            "text": "Reason for Control:"
          },
          {
            "type": "text",
            "text": "RS, AT"
          },
          {
            "type": "html",
            "tag": "TABLE",
            "html": "<TABLE border=\"1\" cellpadding=\"1\" cellspacing=\"1\" class=\"gpo_table\" frame=\"void\" width=\"100%\">\n<THEAD>\n<TR>\n<TH class=\"center\">Control(s)</TH>\n<TH class=\"center\">Country Chart\n<br/>(see Supp. No. 1\n<br/>to part 738)</TH>\n</TR>\n</THEAD>\n<TBODY>\n<TR>\n<TD class=\"left\">RS applies entire entry</TD>\n<TD class=\"left\">To or within any destination worldwide. See § 742.6(a)(13).</TD>\n</TR>\n<TR>\n<TD class=\"left\">AT applies to entire entry (4E091)</TD>\n<TD class=\"left\">AT Column 1.</TD>\n</TR>\n</TBODY>\n</TABLE>",
            "text": "Control(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.",
            "id": null
          },
          {
            "type": "text",
            "text": "Control(s)"
          },
          {
            "type": "text",
            "text": "Country Chart"
          },
          {
            "type": "text",
            "text": "(see Supp. No. 1"
          },
          {
            "type": "text",
            "text": "to part 738)"
          },
          {
            "type": "text",
            "text": "RS applies entire entry"
          },
          {
            "type": "text",
            "text": "To or within any destination worldwide. See § 742.6(a)(13)."
          },
          {
            "type": "text",
            "text": "AT applies to entire entry"
          },
          {
            "type": "text",
            "text": "AT Column 1."
          },
          {
            "type": "text",
            "text": "List Based License Exceptions (See Part 740 for a Description of All License Exceptions)"
          },
          {
            "type": "text",
            "text": "TSR:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "AIA:"
          },
          {
            "type": "text",
            "text": "Yes"
          },
          {
            "type": "text",
            "text": "ACM:"
          },
          {
            "type": "text",
            "text": "No"
          },
          {
            "type": "text",
            "text": "Special Conditions for STA"
          },
          {
            "type": "text",
            "text": "STA:"
          },
          {
            "type": "text",
            "text": "License Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR)."
          },
          {
            "type": "text",
            "text": "List of Items Controlled"
          },
          {
            "type": "text",
            "text": "Related Controls:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Related Definition:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Items:"
          },
          {
            "type": "text",
            "text": "The list of items controlled is contained in the ECCN heading."
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Technical Notes:</I></HED>\n<P><I>For the purposes of 4E091:</I>\n</P>\n<P><I>1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights.</I>\n</P>\n<P><I>2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP.</I>\n</P>\n<P><I>3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.</I></P></NOTE>",
            "text": "Technical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.",
            "id": null
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Notes:</I></HED>\n<P><I>1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10\n<SU>25</SU> 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher.</I>\n</P>\n<P><I>2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements.</I>\n</P>\n<P><I>2.a. An exporter may determine whether an AI model falls within this exclusion by either:</I>\n</P>\n<P><I>2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or</I>\n</P>\n<P><I>2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.</I></P></NOTE>",
            "text": "Notes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
            "id": null
          }
        ],
        "isEccn": true,
        "boundToParent": false,
        "requireAllChildren": false
      }
    },
    {
      "version": "2025-09-29",
      "fetchedAt": "2025-10-02T20:33:51.399Z",
      "sourceUrl": "https://www.ecfr.gov/api/versioner/v1/full/2025-09-29/title-15?format=xml",
      "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "title": "'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
      "category": "4",
      "group": "4E",
      "supplement": {
        "number": "1",
        "heading": "Supplement No. 1 to Part 774—The Commerce Control List"
      },
      "breadcrumbs": [
        "E. “Technology”"
      ],
      "ancestors": [],
      "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'\n4E091 'Parameters' for an artificial intelligence model trained utilizing 10\n26\nor more 'operations.'\nLicense Requirements\nReason for Control:\nRS, AT\nControl(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.\nControl(s)\nCountry Chart\n(see Supp. No. 1\nto part 738)\nRS applies entire entry\nTo or within any destination worldwide. See § 742.6(a)(13).\nAT applies to entire entry\nAT Column 1.\nList Based License Exceptions (See Part 740 for a Description of All License Exceptions)\nTSR:\nN/A\nAIA:\nYes\nACM:\nNo\nSpecial Conditions for STA\nSTA:\nLicense Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR).\nList of Items Controlled\nRelated Controls:\nN/A\nRelated Definition:\nN/A\nItems:\nThe list of items controlled is contained in the ECCN heading.\nTechnical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.\nNotes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
      "structure": {
        "identifier": "4E091",
        "heading": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "label": "4E091 – 4E091 'Parameters' for an artificial intelligence model trained utilizing 10 26 or more 'operations.'",
        "content": [
          {
            "type": "text",
            "text": "4E091 'Parameters' for an artificial intelligence model trained utilizing 10"
          },
          {
            "type": "text",
            "text": "26"
          },
          {
            "type": "text",
            "text": "or more 'operations.'"
          },
          {
            "type": "text",
            "text": "License Requirements"
          },
          {
            "type": "text",
            "text": "Reason for Control:"
          },
          {
            "type": "text",
            "text": "RS, AT"
          },
          {
            "type": "html",
            "tag": "TABLE",
            "html": "<TABLE border=\"1\" cellpadding=\"1\" cellspacing=\"1\" class=\"gpo_table\" frame=\"void\" width=\"100%\">\n<THEAD>\n<TR>\n<TH class=\"center\">Control(s)</TH>\n<TH class=\"center\">Country Chart\n<br/>(see Supp. No. 1\n<br/>to part 738)</TH>\n</TR>\n</THEAD>\n<TBODY>\n<TR>\n<TD class=\"left\">RS applies entire entry</TD>\n<TD class=\"left\">To or within any destination worldwide. See § 742.6(a)(13).</TD>\n</TR>\n<TR>\n<TD class=\"left\">AT applies to entire entry (4E091)</TD>\n<TD class=\"left\">AT Column 1.</TD>\n</TR>\n</TBODY>\n</TABLE>",
            "text": "Control(s) Country Chart (see Supp. No. 1 to part 738) RS applies entire entry To or within any destination worldwide. See § 742.6(a)(13). AT applies to entire entry (4E091) AT Column 1.",
            "id": null
          },
          {
            "type": "text",
            "text": "Control(s)"
          },
          {
            "type": "text",
            "text": "Country Chart"
          },
          {
            "type": "text",
            "text": "(see Supp. No. 1"
          },
          {
            "type": "text",
            "text": "to part 738)"
          },
          {
            "type": "text",
            "text": "RS applies entire entry"
          },
          {
            "type": "text",
            "text": "To or within any destination worldwide. See § 742.6(a)(13)."
          },
          {
            "type": "text",
            "text": "AT applies to entire entry"
          },
          {
            "type": "text",
            "text": "AT Column 1."
          },
          {
            "type": "text",
            "text": "List Based License Exceptions (See Part 740 for a Description of All License Exceptions)"
          },
          {
            "type": "text",
            "text": "TSR:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "AIA:"
          },
          {
            "type": "text",
            "text": "Yes"
          },
          {
            "type": "text",
            "text": "ACM:"
          },
          {
            "type": "text",
            "text": "No"
          },
          {
            "type": "text",
            "text": "Special Conditions for STA"
          },
          {
            "type": "text",
            "text": "STA:"
          },
          {
            "type": "text",
            "text": "License Exception STA may not be used to ship or transmit “technology” specified by ECCN 4E091 to any of the destinations listed in Country Group A:5 or A:6 (See Supplement No.1 to part 740 of the EAR)."
          },
          {
            "type": "text",
            "text": "List of Items Controlled"
          },
          {
            "type": "text",
            "text": "Related Controls:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Related Definition:"
          },
          {
            "type": "text",
            "text": "N/A"
          },
          {
            "type": "text",
            "text": "Items:"
          },
          {
            "type": "text",
            "text": "The list of items controlled is contained in the ECCN heading."
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Technical Notes:</I></HED>\n<P><I>For the purposes of 4E091:</I>\n</P>\n<P><I>1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights.</I>\n</P>\n<P><I>2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP.</I>\n</P>\n<P><I>3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.</I></P></NOTE>",
            "text": "Technical Notes: For the purposes of 4E091: 1. 'Parameters' refers to any value learned during training (e.g., network weights, biases, etc.). 'Parameters' for an artificial intelligence model are also known as model weights. 2. 'Operations' refers to mathematical operations used for pre-training and any subsequent training, such as fine-tuning the pre-trained model, but does not include the collection and curation of the input training data. Training 'operations' should account for operations required to perform all steps in the pre-training and subsequent training process, including those for forward and backward propagation for all relevant layers, pooling, and convolutions, regardless of the implementation and hardware limitations, and applied to all relevant operations. For example, consider a model composed of a single densely connected layer with I input neurons, O output neurons, and no biases being trained with backpropagation. Such a model would have a total of N = I * O learned parameters. Each forward pass would require N multiply accumulate operations, or (assuming floating point arithmetic) 2N FLOP. Each backward pass would require 2N multiply accumulate operations, or 4N FLOP. Then, in total, each training data point would require 6N FLOP. Training on a data set of size D would require 6ND total FLOP. 3. If more than ten percent of the 'operations' involve training on data that was not “published” as defined in § 734.7(a) and was generated by a single data-generation model, then 'operations' the data-generation model used to generate the data should be counted, and if the data-generation model's 'parameters' were not “published,” then the training 'operations' used to train the data-generating model should be counted as well. A single data-generation model includes variants of the same model, such as different checkpoints or fine-tuned variants. If multiple models with 'parameters' that were not “published” were used to generate data used for more than ten percent of the training 'operations,' then only the training 'operations' of the data-generation model using the most training 'operations' should be counted. No actual training 'operation' should be counted more than once, so if data-generation model A is used to train data-generation model B and data-generation model C, and models B and C are used to train model D, then the operations to train A are only added to the number of operations for model D once.",
            "id": null
          },
          {
            "type": "html",
            "tag": "NOTE",
            "html": "<NOTE>\n<HED><I>Notes:</I></HED>\n<P><I>1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10\n<SU>25</SU> 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher.</I>\n</P>\n<P><I>2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements.</I>\n</P>\n<P><I>2.a. An exporter may determine whether an AI model falls within this exclusion by either:</I>\n</P>\n<P><I>2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or</I>\n</P>\n<P><I>2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.</I></P></NOTE>",
            "text": "Notes: 1. In accordance with § 734.7 of the EAR, 4E091 does not control the 'parameters' of any artificial intelligence model that have been “published” as defined in § 734.7(a). 4E091 also does not control the 'parameters' of any artificial intelligence model derived from a model whose parameters have been 'published,' except where the model has been derived using additional training 'operations' that constitute more than 2.5 × 10 25 'operations' or more than 25 percent of the training 'operations' defined in Note 2, whichever is higher. 2. 4E091 does not control the 'parameters' of any artificial intelligence model trained utilizing fewer 'operations' than the number needed, based on the most efficient “published” methods to train artificial intelligence models, to train an artificial intelligence model as capable, according to an aggregate of widely used benchmarks, as the most advanced artificial intelligence model that has been “published” as defined in § 734.7(a) of the EAR. To provide certainty for this exclusion, the number of 'operations' needed should not decrease with algorithmic improvements. 2.a. An exporter may determine whether an AI model falls within this exclusion by either: 2.a.1. Self classifying by relying on guidance published by BIS or technical opinions issued by the U.S. AI Safety Institute and the Department of Energy, should such opinions have been published, or 2.a.2. A classification request to BIS in accordance with the procedures in §§ 748.1 and 748.3 of the EAR.",
            "id": null
          }
        ],
        "isEccn": true,
        "boundToParent": false,
        "requireAllChildren": false
      }
    }
  ]
}